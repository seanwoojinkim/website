{
  "permissions": {
    "allow": [
      "Bash(find:*)",
      "Bash(bin/rails runner:*)",
      "Bash(docker compose exec:*)",
      "Bash(claude task create:*)",
      "Bash(bash:*)",
      "Bash(docker compose:*)",
      "Bash(./hack/spec_metadata.sh:*)",
      "Bash(git checkout:*)",
      "Bash(chmod:*)",
      "Bash(./hack/generate_frontmatter.sh:*)",
      "Bash(mkdir:*)",
      "Bash(curl:*)",
      "Bash(cat:*)",
      "Bash(bundle list:*)",
      "Bash(gem list)",
      "Bash(docker-compose exec rails-mrp-api gem:*)",
      "Bash(git log:*)",
      "Bash(git init:*)",
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "Bash(git remote add:*)",
      "Bash(git branch:*)",
      "WebSearch",
      "Bash(claude-agent academic-researcher \"Research academic literature on vector similarity algorithms for recommendation systems.\n\nFocus areas:\n- Mathematical foundations and computational complexity of similarity metrics (cosine similarity, Euclidean distance, dot product, Manhattan distance, Jaccard similarity)\n- Theoretical trade-offs between different distance metrics in high-dimensional spaces\n- Academic studies comparing algorithm performance and accuracy\n- Approximate Nearest Neighbor (ANN) algorithm theory: HNSW, IVF, LSH, Product Quantization\n- Embedding space theory and dimensionality considerations\n- Research on scalability and computational complexity (time/space trade-offs)\n\nDepth: Deep (this is foundational theory requiring thorough academic investigation)\nKey concepts: vector similarity, distance metrics, ANN algorithms, computational complexity, embedding spaces, curse of dimensionality\nTimeframe: Include foundational papers (2010+) and recent advances (2020-2025)\n\nReturn: Peer-reviewed studies, algorithm complexity analysis, comparative benchmarks, theoretical foundations, consensus areas and debates\")",
      "Bash(claude-agent industry-researcher \"Research industry practices and expert insights on vector-based recommendation systems at scale.\n\nFocus areas:\n- How Netflix, Spotify, YouTube, Amazon implement vector similarity for recommendations\n- Real-world architecture patterns: two-tower models, bi-encoders, embedding generation pipelines\n- Production implementations using FAISS, HNSW, Annoy, ScaNN, and vector databases (Pinecone, Milvus, Qdrant, Weaviate)\n- Performance optimization strategies: GPU acceleration, distributed search, caching, index tuning\n- Scaling considerations: billion-scale datasets, latency requirements, throughput optimization\n- Trade-offs between accuracy (recall) and speed in production systems\n- Infrastructure costs and resource utilization patterns\n- Best practices for embedding model training and deployment\n\nDepth: Deep (comprehensive investigation of production systems and scaling strategies)\nTarget sources: Engineering blogs from major tech companies, conference talks (RecSys, KDD), vector database vendor documentation, case studies with metrics\nEvidence type: Architecture diagrams, performance metrics, implementation patterns, post-mortems, benchmark comparisons\n\nReturn: Production architectures, case studies with metrics, scaling strategies, best practices, expert recommendations, cost/performance trade-offs\")",
      "WebFetch(domain:arxiv.org)",
      "WebFetch(domain:engineering.atspotify.com)",
      "WebFetch(domain:netflixtechblog.com)",
      "WebFetch(domain:blog.algomaster.io)",
      "WebFetch(domain:api7.ai)",
      "WebFetch(domain:konghq.com)",
      "WebFetch(domain:gist.github.com)",
      "WebFetch(domain:github.blog)"
    ],
    "deny": [],
    "ask": []
  }
}
